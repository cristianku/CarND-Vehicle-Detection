{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import sklearn.svm as svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "class save_images ( object ):\n",
    "    def __init__( self ):\n",
    "        self.i = 0\n",
    "    def __call__( self, image):\n",
    "        # do something\n",
    "        self.i +=1\n",
    "        cv2.imwrite(\"test_images2/image\" + str(self.i) + \".jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        return image\n",
    "    \n",
    "save_images = save_images()    \n",
    "    \n",
    "## creating additional test images\n",
    "from moviepy.editor import VideoFileClip\n",
    "output_video_name = 'test_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "clip2 = clip1.subclip(0,2)\n",
    "output_video = clip2.fl_image(save_images) #NOTE: this function expects color images!!\n",
    "%time output_video.write_videofile(output_video_name, audio=False)\n",
    "import os\n",
    "os.remove('test_video_output.mp4')\n",
    "print (\"Completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_features_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class image_features_extractor:\n",
    "    def __init__(self    \\\n",
    "        ,color_space = 'HSV'      # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "        ,orient = 9               # HOG orientations \n",
    "        ,pix_per_cell = 7         # HOG pixels per cell \n",
    "        ,cell_per_block = 2       # HOG cells per block \n",
    "        ,spatial_size = (32, 32)  # Spatial binning dimensions\n",
    "        ,spatial_feat = True     # Spatial features on or off\n",
    "        ,hist_feat = True        # Histogram features on or off\n",
    "        ,hog_feat = True          # HOG features on or off\n",
    "        ,nbins=32                 # Number of color histogram bins\n",
    "        ,bins_range=(0, 256)\n",
    "                ):\n",
    "\n",
    "        self.color_space = color_space\n",
    "        self.orient = orient\n",
    "        self.pix_per_cell = pix_per_cell\n",
    "        self.cell_per_block = cell_per_block\n",
    "        self.spatial_size = spatial_size\n",
    "        self.spatial_feat = spatial_feat\n",
    "        self.hist_feat = hist_feat\n",
    "        self.hog_feat = hog_feat\n",
    "        self.nbins=nbins\n",
    "        self.bins_range=bins_range\n",
    "        \n",
    "\n",
    "    # Define a function to compute binned color features  \n",
    "    def bin_spatial(self,feature_image):\n",
    "        # Use cv2.resize().ravel() to create the feature vector\n",
    "        features = cv2.resize(feature_image, self.spatial_size).ravel() \n",
    "        # Return the feature vector\n",
    "        return features\n",
    "\n",
    "    # Define a function to compute color histogram features  \n",
    "    def color_hist(self,feature_image):\n",
    "        # Compute the histogram of the color channels separately\n",
    "        channel1_hist = np.histogram(feature_image[:,:,0], bins=self.nbins, range=self.bins_range)\n",
    "        channel2_hist = np.histogram(feature_image[:,:,1], bins=self.nbins, range=self.bins_range)\n",
    "        channel3_hist = np.histogram(feature_image[:,:,2], bins=self.nbins, range=self.bins_range)\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "        # Return the individual histograms, bin_centers and feature vector\n",
    "        return hist_features\n",
    "\n",
    "    def get_hog_features(self, feature_image, visualise=False):\n",
    "        if visualise:\n",
    "            # feature_image is 1 channel image\n",
    "            hog_features, hog_image     = hog(feature_image, \n",
    "                                  orientations=self.orient, \n",
    "                                  pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                                  cells_per_block=(self.cell_per_block, self.cell_per_block), \n",
    "                                  block_norm='L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "            return hog_features, hog_image\n",
    "\n",
    "        \n",
    "        else:\n",
    "            # feature_image is 1 channel image\n",
    "            hog_features     = hog(feature_image, \n",
    "                                  orientations=self.orient, \n",
    "                                  pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                                  cells_per_block=(self.cell_per_block, self.cell_per_block), \n",
    "                                  block_norm='L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=False, feature_vector=True)\n",
    "            return hog_features\n",
    "\n",
    "\n",
    "\n",
    "    def get_all_features (self, img):\n",
    "        if self.color_space != 'RGB':\n",
    "            if self.color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            elif self.color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "            elif self.color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            elif self.color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "            elif self.color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else: \n",
    "            feature_image = np.copy(img)\n",
    "\n",
    "\n",
    "        img_features = []\n",
    "\n",
    "        if self.spatial_feat == True:\n",
    "            img_features.append(self.bin_spatial(feature_image))\n",
    "\n",
    "        if self.hist_feat == True:\n",
    "            img_features.append(self.color_hist(feature_image))\n",
    "            \n",
    "        if self.hog_feat == True:\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                temp = self.get_hog_features(feature_image[:,:,channel])\n",
    "                hog_features.extend(temp)      \n",
    "            img_features.append(hog_features)\n",
    "\n",
    "        #9) Return concatenated array of features\n",
    "    #     print (img_features)\n",
    "        return np.concatenate(img_features)                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Detector from images ( train & prediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class image_car_detector:\n",
    "    def __init__(self, extractor, \n",
    "                 cars_folder='vehicles', \n",
    "                 notcars_folder='non-vehicles',\n",
    "                 limit_images=None):\n",
    "        self.cars_folder    = cars_folder\n",
    "        self.notcars_folder = notcars_folder\n",
    "\n",
    "        self.car_images_list     = []\n",
    "        self.notcars_images_list = []\n",
    "        self.extractor = extractor\n",
    "        \n",
    "        self.car_features = []\n",
    "        self.notcar_features = []\n",
    "        self.limit_images = limit_images\n",
    "\n",
    "        \n",
    "    def load_images_list(self):\n",
    "        self.car_images_list     = []\n",
    "        self.notcars_images_list = []\n",
    "    \n",
    "        # loading cars\n",
    "        for subfolder in glob.glob(self.cars_folder + '/*'):\n",
    "          print (\"subfolder = \" + subfolder)\n",
    "          for image  in  glob.glob(subfolder+'/*'):\n",
    "               self.car_images_list.append(image)\n",
    "\n",
    "        # loading non cars\n",
    "        for subfolder in glob.glob(self.notcars_folder+ '/*'):\n",
    "          for image  in  glob.glob(subfolder+'/*'):\n",
    "               self.notcars_images_list.append(image)\n",
    "    \n",
    "    # Define a function to extract features from a list of images\n",
    "    # Have this function call bin_spatial() and color_hist()\n",
    "    def extract_imgs_features(self):\n",
    "        # Iterate through the list of images\n",
    "        if self.limit_images:\n",
    "            x_limit = self.limit_images\n",
    "            print (\" limiting the number of images to \" + str(x_limit))\n",
    "        else:\n",
    "            x_limit = len(self.car_images_list)\n",
    "            print (\" processing \" + str(x_limit) +\" images \"  )\n",
    "\n",
    "\n",
    "        print ( \" \")\n",
    "        print (\" Extracting features from cars ....\")\n",
    "        # CARS FEATURES \n",
    "        self.car_features = []\n",
    "\n",
    "\n",
    "        for file in self.car_images_list[:x_limit]:\n",
    "            image = cv2.imread(file)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            self.car_features.append(self.extractor.get_all_features(image))\n",
    "        print (\" .. completed \")\n",
    "\n",
    "            \n",
    "        print ( \" \")\n",
    "        print (\" Extracting features from non cars ....\")\n",
    "        # NOT CAR FEATURES \n",
    "        self.notcar_features = []\n",
    "        # Iterate through the list of images\n",
    "        for file in self.notcars_images_list[:x_limit]:\n",
    "            image = cv2.imread(file)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            self.notcar_features.append(self.extractor.get_all_features(image))\n",
    "        print (\" .. completed \")\n",
    "        print (\" \")\n",
    "\n",
    "        \n",
    "    def detector_train(self, parameters=[1, 10]):\n",
    "        print ( \"Starting the training ....\")\n",
    "        if len(self.car_features) == 0:\n",
    "            print ( \" ... extracting the features \")\n",
    "            self.extract_imgs_features()\n",
    "        \n",
    "        X = np.vstack((self.car_features, self.notcar_features)).astype(np.float64)                        \n",
    "\n",
    "        print (\".....Scaling...\")\n",
    "        # Fit a per-column scaler\n",
    "        self.X_scaler = StandardScaler().fit(X)\n",
    "        # Apply the scaler to X\n",
    "        scaled_X = self.X_scaler.transform(X)\n",
    "        \n",
    "        y = np.hstack((np.ones(len(self.car_features)), np.zeros(len(self.notcar_features))))\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Split up data into randomized training and test sets\n",
    "        rand_state = np.random.randint(0, 100)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "        \n",
    "        from sklearn.svm import LinearSVC\n",
    "        import time\n",
    "\n",
    "#         self.svr = svm.LinearSVC()\n",
    "\n",
    "\n",
    "        # Check the training time for the SVC\n",
    "        print ( \"Start training ... \")\n",
    "        t=time.time()\n",
    "#         param_grid = {'C': parameters}\n",
    "#         self.clf = GridSearchCV(self.svr , param_grid=param_grid)\n",
    "        self.clf = LinearSVC()\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "        t2 = time.time()\n",
    "        print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "        # Check the score of the SVC\n",
    "        print('Test Accuracy of SVC = ', round(self.clf.score(X_test, y_test), 4))\n",
    "\n",
    "    def save_classifier(self):\n",
    "        import pickle\n",
    "        # save the classifier\n",
    "        with open('car_detection_classifier.pkl', 'wb') as fid:\n",
    "            pickle.dump(self.clf, fid) \n",
    "            \n",
    "        with open('X_scaler.pkl', 'wb') as fid:\n",
    "            pickle.dump(self.X_scaler, fid) \n",
    "        print (\" .. classifier saved \")    \n",
    "\n",
    "    def load_classifier(self):\n",
    "        import pickle\n",
    "        # save the classifier\n",
    "        with open('car_detection_classifier.pkl', 'rb') as fid:\n",
    "            self.clf = pickle.load(fid)\n",
    "        with open('X_scaler.pkl', 'rb') as fid:\n",
    "            self.X_scaler = pickle.load(fid)\n",
    "\n",
    "        print (\" .. classifier loaded \")    \n",
    "\n",
    "\n",
    "    def search_windows(self, img, windows):\n",
    "        self.on_windows = []\n",
    "        for window in windows:\n",
    "#             print (window)\n",
    "            #3) Extract the test window from original image\n",
    "            test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "            #4) Extract features for that window using single_img_features()\n",
    "            features = self.extractor.get_all_features(test_img)\n",
    "            #5) Scale extracted features to be fed to classifier\n",
    "            test_features = self.X_scaler.transform(np.array(features).reshape(1, -1))\n",
    "            \n",
    "            #6) Predict using your classifier\n",
    "            prediction = self.clf.predict(test_features)\n",
    "            #7) If positive (prediction == 1) then save the window\n",
    "            if prediction == 1:\n",
    "                self.on_windows.append(window)\n",
    "#                 print ( \"prediction = 1 \")\n",
    "#                 plt.title(\"prediction = 1 \")\n",
    "#             else:\n",
    "#                 plt.title(\"prediction = 0 \")\n",
    "\n",
    "#             plt.axis('off')\n",
    "#             plt.imshow(test_img)\n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "                \n",
    "        return self.on_windows\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('vehicles/GTI_Far/image0022.png')\n",
    "# image = cv2.imread('test_images/test1.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# color space = RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "extractor = image_features_extractor(color_space='YCrCb',\n",
    "                                     pix_per_cell=8,\n",
    "                                     cell_per_block=2,\n",
    "                                     \n",
    "                                     orient=9)\n",
    "hog_features, image_tmp = extractor.get_hog_features(image[:,:,2], visualise=True)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(image_tmp,cmap='gray')\n",
    "plt.show()\n",
    "print ( len(hog_features))\n",
    "print(np.array(hog_features).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractor = image_features_extractor(color_space='YCrCb'\n",
    "                                    ,pix_per_cell=8\n",
    "                                    ,cell_per_block=2\n",
    "                                     \n",
    "                                    ,orient=9\n",
    "                                    ,spatial_feat = True     # Spatial features on or off\n",
    "                                    ,hist_feat = True        # Histogram features on or off\n",
    "                                    ,hog_feat = True  \n",
    "                                    ,spatial_size = (16, 16)\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "detector = image_car_detector(extractor) #, limit_images= 2000)\n",
    "\n",
    "# detector.load_images_list()\n",
    "\n",
    "# detector.extract_imgs_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(detector.car_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector.detector_train()\n",
    "\n",
    "# detector.save_classifier()\n",
    "\n",
    "detector.load_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class window_extractor:\n",
    "    def __init__(self, image,               \\\n",
    "                 x_start_stop=[None, None], \\\n",
    "                 y_start_stop=[350, None], \\\n",
    "                 window_dimension=64,  \\\n",
    "                 x_overlap=0.5, y_overlap=0.5):\n",
    "        \n",
    "        self.image           = image\n",
    "        self.xy_window       = (window_dimension, window_dimension)\n",
    "        self.xy_overlap      = (x_overlap, y_overlap)\n",
    "        self.x_start_stop    = x_start_stop\n",
    "        self.y_start_stop    = y_start_stop\n",
    "        \n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        #     print (x_start_stop)\n",
    "        if self.x_start_stop[0] == None:\n",
    "            self.x_start_stop[0] = 0\n",
    "        if self.x_start_stop[1] == None:\n",
    "            self.x_start_stop[1] = self.image.shape[1]\n",
    "        if self.y_start_stop[0] == None:\n",
    "            self.y_start_stop[0] = 0\n",
    "        if self.y_start_stop[1] == None:\n",
    "            self.y_start_stop[1] = self.image.shape[0]\n",
    "\n",
    "        # Compute the span of the region to be searched    \n",
    "        self.xspan = self.x_start_stop[1] - self.x_start_stop[0]\n",
    "        self.yspan = self.y_start_stop[1] - self.y_start_stop[0]\n",
    "        \n",
    "        # Compute the number of pixels per step in x/y\n",
    "        self.nx_pix_per_step = np.int(self.xy_window[0]*(1 - self.xy_overlap[0]))\n",
    "        self.ny_pix_per_step = np.int(self.xy_window[1]*(1 - self.xy_overlap[1]))\n",
    "        \n",
    "        # Compute the number of windows in x/y\n",
    "        self.nx_buffer = np.int(self.xy_window[0]*(self.xy_overlap[0]))\n",
    "        self.ny_buffer = np.int(self.xy_window[1]*(self.xy_overlap[1]))\n",
    "        self.nx_windows = np.int((self.xspan-self.nx_buffer)/self.nx_pix_per_step) \n",
    "        self.ny_windows = np.int((self.yspan-self.ny_buffer)/self.ny_pix_per_step) \n",
    "\n",
    "\n",
    "\n",
    "    def get_windows(self):\n",
    "        # Initialize a list to append window positions to\n",
    "        self.window_list = []\n",
    "        # Loop through finding x and y window positions\n",
    "        # Note: you could vectorize this step, but in practice\n",
    "        # you'll be considering windows one by one with your\n",
    "        # classifier, so looping makes sense\n",
    "        for ys in range(self.ny_windows):\n",
    "            for xs in range(self.nx_windows):\n",
    "                # Calculate window position\n",
    "                startx = xs*self.nx_pix_per_step + self.x_start_stop[0]\n",
    "                endx = startx + self.xy_window[0]\n",
    "                starty = ys*self.ny_pix_per_step + self.y_start_stop[0]\n",
    "                endy = starty + self.xy_window[1]\n",
    "                # Append window position to list\n",
    "                self.window_list.append(((startx, starty), (endx, endy)))\n",
    "        # Return the list of windows\n",
    "        return self.window_list\n",
    "    \n",
    "    def draw_boxes(self,hot_windows, color=(0, 0, 255), thick=6):\n",
    "        # Make a copy of the image\n",
    "        imcopy = np.copy(self.image)\n",
    "        tmp_window_list = hot_windows\n",
    "        for bbox in tmp_window_list:\n",
    "#             print (\"bbox = \" + str(bbox))\n",
    "            # Draw a rectangle given bbox coordinates\n",
    "            cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "        # Return the image copy with boxes drawn\n",
    "        return imcopy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = mpimg.imread('test_images/test3.jpg')\n",
    "\n",
    "windows = []\n",
    "\n",
    "##########  scale = 1\n",
    "windows_tmp = window_extractor(image, \n",
    "                               window_dimension=int(64), \n",
    "                               x_overlap = 0.7,\n",
    "                               y_overlap = 0.7,\n",
    "                               x_start_stop = [340,None],\n",
    "                               y_start_stop = [400,496]).get_windows()\n",
    "for x in windows_tmp:\n",
    "     windows.append(x)\n",
    "        \n",
    "# ###########  scale = 1.25      \n",
    "# windows_tmp = window_extractor(image, \n",
    "#                                window_dimension=int(64*1.25), \n",
    "#                                y_overlap = 0.5,\n",
    "#                                y_start_stop = [400,550]).get_windows()\n",
    "# for x in windows_tmp:\n",
    "#      windows.append(x)\n",
    "\n",
    "# ###########  scale = 1.5     \n",
    "# windows_tmp = window_extractor(image, \n",
    "#                                window_dimension=int(64*1.5), \n",
    "#                                y_overlap = 0.5,x_overlap=0.6,\n",
    "#                                y_start_stop = [400,592]).get_windows()\n",
    "# for x in windows_tmp:\n",
    "#      windows.append(x)\n",
    "\n",
    "# ###########  scale = 1.75     \n",
    "# windows_tmp = window_extractor(image, \n",
    "#                                window_dimension=int(64*1.9), \n",
    "#                                y_overlap = 0.5,x_overlap=0.6,\n",
    "#                                y_start_stop = [400,656]).get_windows()\n",
    "# for x in windows_tmp:\n",
    "#      windows.append(x)\n",
    "\n",
    "\n",
    "        \n",
    "hot_windows = detector.search_windows( image, windows)\n",
    "\n",
    "print (\" all boxes\")\n",
    "plt.imshow(window_extractor(image).draw_boxes(windows))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print (\" recognized cars boxes\")\n",
    "plt.imshow(window_extractor(image).draw_boxes(hot_windows))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "class heat_map:\n",
    "    def __init__(self, boxes_list, image):\n",
    "            self.boxes = boxes_list\n",
    "            self.heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "            self.image = np.copy(image)\n",
    "            \n",
    "    \n",
    "    def add_heat(self):\n",
    "        # Iterate through list of bboxes\n",
    "        \n",
    "        for box in self.boxes :\n",
    "#             print (\"box = \" + str(box))\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            self.heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "        # Return updated heatmap\n",
    "\n",
    "    def apply_threshold(self,threshold):\n",
    "        print (\" Applying threshold = \" + str(threshold))\n",
    "        # Zero out pixels below the threshold\n",
    "        self.heatmap[self.heatmap < threshold] = 0\n",
    "        # Return thresholded map\n",
    "\n",
    "    def draw_labeled_bboxes(self):\n",
    "        print (\"draw_labeled_bboxes .... \")\n",
    "        #scipy.ndimage.measurements.label\n",
    "        self.labels = label(self.heatmap)\n",
    "#         print (\"labels = \" + str(labels))\n",
    "        # Iterate through all detected cars\n",
    "        self.boxes = []\n",
    "        for car_number in range(1, self.labels[1]+1):\n",
    "            print ( \" car_number = \" + str(car_number))\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (self.labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(self.image, bbox[0], bbox[1], (0,255,0), 6)\n",
    "            self.boxes.append(bbox)\n",
    "        # Return the image\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = heat_map(hot_windows, image)\n",
    "heat.add_heat()\n",
    "heat.apply_threshold(threshold=1)\n",
    "heat.draw_labeled_bboxes()\n",
    "\n",
    "# print(heat.heatmap.nonzero())\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "# Turn off tick labels\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax2.imshow(heat.image)\n",
    "ax2.set_title('Identified cars', fontsize=50)\n",
    "# Turn off tick labels\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now i am trying to refine the boxes found putting more sliding windows around of the detected vehicles, \n",
    "### to better include the car in a correct box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.boxes\n",
    "\n",
    "for box in heat.boxes:\n",
    "    print (box)\n",
    "    print (box[0][1])\n",
    "    print (box[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_new = []\n",
    "\n",
    "for box in heat.boxes:\n",
    "    x_start = int((box[0][0] ) * .95)\n",
    "    x_stop  = int((box[1][0] ) * 1.05)\n",
    "    y_start = int((box[0][1] ) * .95)\n",
    "    y_stop  = int((box[1][1] ) * 1.05)\n",
    "    \n",
    "    ##########  scale = 1\n",
    "    windows_tmp_new = window_extractor(image, \n",
    "                                   window_dimension=64,\n",
    "                                   x_overlap = 0.9,\n",
    "                                   y_overlap = 0.9,\n",
    "                                   x_start_stop = [x_start,x_stop],\n",
    "                                   y_start_stop = [y_start,y_stop]).get_windows()\n",
    "    for x in windows_tmp_new:\n",
    "         windows_new.append(x)\n",
    "            \n",
    "hot_windows_new = detector.search_windows( image, windows_new)\n",
    "\n",
    "print (\" all boxes\")\n",
    "plt.imshow(window_extractor(image).draw_boxes(windows_new))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print (\" recognized cars boxes\")\n",
    "plt.imshow(window_extractor(image).draw_boxes(hot_windows_new))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_new = heat_map(hot_windows_new, image)\n",
    "heat_new.add_heat()\n",
    "heat_new.apply_threshold(threshold=3)\n",
    "heat_new.draw_labeled_bboxes()\n",
    "\n",
    "# print(heat.heatmap.nonzero())\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "# Turn off tick labels\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax2.imshow(heat_new.image)\n",
    "ax2.set_title('Identified cars', fontsize=50)\n",
    "# Turn off tick labels\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "heat.draw_labeled_bboxes()\n",
    "plt.imshow(heat.image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defining the class pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    def __init__(self, debug=False):\n",
    "        self.detector = image_car_detector(image_features_extractor\n",
    "                                               (color_space='YCrCb'\n",
    "                                                ,pix_per_cell=8\n",
    "                                                ,cell_per_block=2\n",
    "                                                ,orient=9\n",
    "                                                ,spatial_feat = True     # Spatial features on or off\n",
    "                                                ,hist_feat = True        # Histogram features on or off\n",
    "                                                ,hog_feat = True  \n",
    "                                                ,spatial_size = (16, 16)\n",
    "                                            )\n",
    "                                           )\n",
    "        self.detector.load_classifier()\n",
    "        self.debug= debug\n",
    "        \n",
    "    def set_image(self, image):\n",
    "            self.image = image\n",
    "            \n",
    "    def searchfor_windows_first(self):\n",
    "            self.windows = []\n",
    "            ##########  scale = 1\n",
    "            windows_ext = window_extractor(self.image, \n",
    "                                           window_dimension=80, \n",
    "                                           x_overlap = 0.3,\n",
    "                                           y_overlap = 0.3,\n",
    "                                           x_start_stop = [340,None],\n",
    "                                           y_start_stop = [400,496])\n",
    "            \n",
    "            for x in windows_ext.get_windows():\n",
    "                 self.windows.append(x)\n",
    "\n",
    "            ##########  scale = 1.25      \n",
    "            windows_ext = window_extractor(image, \n",
    "                                           window_dimension=int(80*1.25), \n",
    "                                           x_overlap = 0.3,\n",
    "                                           y_overlap = 0.3,\n",
    "                                           x_start_stop = [340,None],\n",
    "                                           y_start_stop = [400,550])\n",
    "            for x in windows_ext.get_windows():\n",
    "                 self.windows.append(x)\n",
    "\n",
    "\n",
    "            # ###########  scale = 1.5     \n",
    "            windows_ext = window_extractor(image, \n",
    "                                           window_dimension=int(80*1.5), \n",
    "                                           x_overlap = 0.3,\n",
    "                                           y_overlap = 0.3,\n",
    "                                           x_start_stop = [340,None],\n",
    "                                           y_start_stop = [400,600])\n",
    "            for x in windows_ext.get_windows():\n",
    "                 self.windows.append(x)\n",
    "\n",
    "        \n",
    "            # ###########  scale = 1.75   \n",
    "            windows_ext = window_extractor(image, \n",
    "                                           window_dimension=int(80*1.75), \n",
    "                                           x_overlap = 0.3,\n",
    "                                           y_overlap = 0.3,\n",
    "                                           x_start_stop = [340,None],\n",
    "                                           y_start_stop = [400,656])\n",
    "            for x in windows_ext.get_windows():\n",
    "                 self.windows.append(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def searchfor_windows_second(self, \n",
    "                                 x_overlap=None,\n",
    "                                 y_overlap=None,\n",
    "                                 x_start_stop=None,\n",
    "                                 y_start_stop=None\n",
    "                                ):\n",
    "            windows_ext = window_extractor(self.image, \n",
    "                                           window_dimension=int(64), \n",
    "                                           x_overlap = 0.9,\n",
    "                                           y_overlap = 0.9,\n",
    "                                           x_start_stop=x_start_stop,\n",
    "                                           y_start_stop=y_start_stop)\n",
    "            \n",
    "            for x in windows_ext.get_windows():\n",
    "                 self.windows.append(x)\n",
    "        \n",
    "            if self.debug:\n",
    "                image_tmp = windows_ext.draw_boxes(self.windows)\n",
    "                return image_tmp\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "\n",
    "\n",
    "    # search with different steps\n",
    "    # first search is with big windows and low number of windows to get a speed overview of the car positions\n",
    "    # secondly using the car position I will \"shut\" more smaller sliding windows in that area to find the \n",
    "    #          exact box around the car\n",
    "    def search_cars_by_steps(self):\n",
    "        \n",
    "        ######################################################\n",
    "        ##              FIRST         STEP\n",
    "        ######################################################\n",
    "\n",
    "        self.windows = []\n",
    "        self.hot_windows = []\n",
    "        \n",
    "        ########\n",
    "        # creating a list of boxes\n",
    "        ########\n",
    "        tmp_image = self.searchfor_windows_first()\n",
    "        if self.debug:\n",
    "            image_tmp = window_extractor(self.image).draw_boxes(self.windows)\n",
    "            plt.imshow(image_tmp)    \n",
    "            plt.title(\" Boxes drawn on the image \")\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "        ########\n",
    "        # search for car detection in the above calculated boxes\n",
    "        ########\n",
    "        self.hot_windows = []\n",
    "        self.hot_windows = self.detector.search_windows(self.image, self.windows)\n",
    "        if self.debug:\n",
    "            tmp_image_hot = window_extractor(self.image).draw_boxes(self.hot_windows)\n",
    "            plt.imshow(tmp_image_hot)    \n",
    "            plt.title(\" Car boxes detected \")\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "        ########\n",
    "        # heat map\n",
    "        ########\n",
    "        self.heat = heat_map(self.hot_windows, self.image)\n",
    "        self.heat.add_heat()\n",
    "        self.heat.apply_threshold(threshold=1)\n",
    "#         self.heat.draw_labeled_bboxes()\n",
    "\n",
    "        if self.debug:\n",
    "            self.heat.draw_labeled_bboxes()\n",
    "            plt.imshow(self.heat.image)    \n",
    "            plt.title(\" First heat map\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# #         return tmp_image, tmp_image_hot, self.heat.image\n",
    "\n",
    "\n",
    "        ######################################################\n",
    "        ##              SECOND         STEP\n",
    "        ######################################################\n",
    "\n",
    "\n",
    "        if self.debug: print ( \" Second Step ....\")\n",
    "        self.windows = []\n",
    "        for box in self.heat.boxes:\n",
    "            x_start = int((box[0][0] ) * .95)\n",
    "            x_stop  = int((box[1][0] ) * 1.05)\n",
    "            y_start = int((box[0][1] ) * .95)\n",
    "            y_stop  = int((box[1][1] ) * 1.05)\n",
    "\n",
    "            print (\" box = \" + \"x_start= \" + str(x_start) +  \" , \"  \n",
    "                             + \"x_stop= \"  + str(x_stop)  +  \" , \"  \n",
    "                             + \"y_start= \" + str(y_start) +  \" , \"  \n",
    "                             + \"y_stop= \"  + str(y_stop)  +  \" , \"  \n",
    "                  )\n",
    "            # creating a list of boxes\n",
    "            self.searchfor_windows_second(\n",
    "                                           x_overlap = 0.7,\n",
    "                                           y_overlap = 0.7,\n",
    "                                           x_start_stop=[x_start,x_stop],\n",
    "                                           y_start_stop=[y_start,y_stop]\n",
    "                                )\n",
    "\n",
    "        if self.debug:\n",
    "            image_tmp = window_extractor(self.image).draw_boxes(self.windows)\n",
    "            plt.imshow(image_tmp)    \n",
    "            plt.title(\" Boxes drawn on the image (second step )\")\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "        # search for car detection in the above calculated boxes\n",
    "        if self.debug:print (\" Searching for windows with cars \")\n",
    "        if self.debug:print ( \" .. Number of boxes = \" + str(len(self.windows)) )\n",
    "        self.hot_windows = []\n",
    "        self.hot_windows = self.detector.search_windows(self.image, self.windows)\n",
    "        if self.debug:\n",
    "            tmp_image_hot = window_extractor(self.image).draw_boxes(self.hot_windows)\n",
    "            plt.imshow(tmp_image_hot)    \n",
    "            plt.title(\" Car boxes detected \")\n",
    "            plt.show()\n",
    "\n",
    "        ########\n",
    "        # heat map\n",
    "        ########\n",
    "        if self.debug: print (\"Creating heat_map ... \")\n",
    "        self.heat = heat_map(self.hot_windows, self.image)\n",
    "        self.heat.add_heat()\n",
    "        self.heat.apply_threshold(threshold=5)\n",
    "        \n",
    "        if self.debug:\n",
    "            self.heat.draw_labeled_bboxes()\n",
    "            plt.imshow(self.heat.image)    \n",
    "            plt.title(\" Second heat map\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        if self.debug: print(\".... Completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = pipeline(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = mpimg.imread('test_images2/image1.jpg')\n",
    "\n",
    "pipeline1.set_image(image)\n",
    "pipeline1.search_cars_by_steps()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
